{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NFunPbm-0alX"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../Data-processed/crop-recommendation.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EJ40TzKH3Ox4",
        "outputId": "24794ae7-dfc0-4d72-8991-76026b89365e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bc9341d271cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data-processed/crop-recommendation.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data-processed/crop-recommendation.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Le5KpnFd3MS3",
        "outputId": "d81b5fd4-1413-4de6-dee1-d50fcfa01649"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "676zwasH4YAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "id": "3Xj1nYM64dBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "N5tmXPiY4hVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "3_YvXK5E4lwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].unique()"
      ],
      "metadata": {
        "id": "3Bhsa0C_4pMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "BdsVvKE44t0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "qNcneA_B41n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.corr(),annot=True)"
      ],
      "metadata": {
        "id": "OuBMpixS44hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seperating features and target label"
      ],
      "metadata": {
        "id": "k_Qv8gY75Dt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]\n",
        "target = df['label']\n",
        "#features = df[['temperature', 'humidity', 'ph', 'rainfall']]\n",
        "labels = df['label']"
      ],
      "metadata": {
        "id": "wdi348b85LRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialzing empty lists to append all model's name and corresponding name\n",
        "acc = []\n",
        "model = []"
      ],
      "metadata": {
        "id": "iUDW7nET5WtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into train and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_stat"
      ],
      "metadata": {
        "id": "xOk0b6QK5rgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "NvPuNui65tWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DecisionTree = DecisionTreeClassifier(criterion=\"entropy\",random_state=2,max_depth=5)\n",
        "\n",
        "DecisionTree.fit(Xtrain,Ytrain)\n",
        "\n",
        "predicted_values = DecisionTree.predict(Xtest)\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('Decision Tree')\n",
        "print(\"DecisionTrees's Accuracy is: \", x*100)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))\n",
        "DecisionTrees's Accuracy is:  90.0\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "       apple       1.00      1.00      1.00        13\n",
        "      banana       1.00      1.00      1.00        17\n",
        "   blackgram       0.59      1.00      0.74        16\n",
        "    chickpea       1.00      1.00      1.00        21\n",
        "     coconut       0.91      1.00      0.95        21\n",
        "      coffee       1.00      1.00      1.00        22\n",
        "      cotton       1.00      1.00      1.00        20\n",
        "      grapes       1.00      1.00      1.00        18\n",
        "        jute       0.74      0.93      0.83        28\n",
        " kidneybeans       0.00      0.00      0.00        14\n",
        "      lentil       0.68      1.00      0.81        23\n",
        "       maize       1.00      1.00      1.00        21\n",
        "       mango       1.00      1.00      1.00        26\n",
        "   mothbeans       0.00      0.00      0.00        19\n",
        "    mungbean       1.00      1.00      1.00        24\n",
        "   muskmelon       1.00      1.00      1.00        23\n",
        "      orange       1.00      1.00      1.00        29\n",
        "      papaya       1.00      0.84      0.91        19\n",
        "  pigeonpeas       0.62      1.00      0.77        18\n",
        " pomegranate       1.00      1.00      1.00        17\n",
        "        rice       1.00      0.62      0.77        16\n",
        "  watermelon       1.00      1.00      1.00        15\n",
        "\n",
        "    accuracy                           0.90       440\n",
        "   macro avg       0.84      0.88      0.85       440\n",
        "weighted avg       0.86      0.90      0.87       440"
      ],
      "metadata": {
        "id": "uVRJ8t4C53NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "hB0kZMGY6Ue7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation score (Decision Tree)\n",
        "score = cross_val_score(DecisionTree, features, target,cv=5)"
      ],
      "metadata": {
        "id": "ghz2n3j-6XSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "id": "HF29ORac6beq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving trained Decision Tree model"
      ],
      "metadata": {
        "id": "RlPoYP996hrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Dump the trained Naive Bayes classifier with Pickle\n",
        "DT_pkl_filename = '../models/DecisionTree.pkl'\n",
        "# Open the file to save as pkl file\n",
        "DT_Model_pkl = open(DT_pkl_filename, 'wb')\n",
        "pickle.dump(DecisionTree, DT_Model_pkl)\n",
        "# Close the pickle instances\n",
        "DT_Model_pkl.close()"
      ],
      "metadata": {
        "id": "NAUXco0U6nB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guassian Naive Bayes"
      ],
      "metadata": {
        "id": "yOdedY756y3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "NaiveBayes = GaussianNB()\n",
        "\n",
        "NaiveBayes.fit(Xtrain,Ytrain)\n",
        "\n",
        "predicted_values = NaiveBayes.predict(Xtest)\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('Naive Bayes')\n",
        "print(\"Naive Bayes's Accuracy is: \", x)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))\n",
        "Naive Bayes's Accuracy is:  0.990909090909091\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "       apple       1.00      1.00      1.00        13\n",
        "      banana       1.00      1.00      1.00        17\n",
        "   blackgram       1.00      1.00      1.00        16\n",
        "    chickpea       1.00      1.00      1.00        21\n",
        "     coconut       1.00      1.00      1.00        21\n",
        "      coffee       1.00      1.00      1.00        22\n",
        "      cotton       1.00      1.00      1.00        20\n",
        "      grapes       1.00      1.00      1.00        18\n",
        "        jute       0.88      1.00      0.93        28\n",
        " kidneybeans       1.00      1.00      1.00        14\n",
        "      lentil       1.00      1.00      1.00        23\n",
        "       maize       1.00      1.00      1.00        21\n",
        "       mango       1.00      1.00      1.00        26\n",
        "   mothbeans       1.00      1.00      1.00        19\n",
        "    mungbean       1.00      1.00      1.00        24\n",
        "   muskmelon       1.00      1.00      1.00        23\n",
        "      orange       1.00      1.00      1.00        29\n",
        "      papaya       1.00      1.00      1.00        19\n",
        "  pigeonpeas       1.00      1.00      1.00        18\n",
        " pomegranate       1.00      1.00      1.00        17\n",
        "        rice       1.00      0.75      0.86        16\n",
        "  watermelon       1.00      1.00      1.00        15\n",
        "\n",
        "    accuracy                           0.99       440\n",
        "   macro avg       0.99      0.99      0.99       440\n",
        "weighted avg       0.99      0.99      0.99       440"
      ],
      "metadata": {
        "id": "p1BvR57c63TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation score (NaiveBayes)\n",
        "score = cross_val_score(NaiveBayes,features,target,cv=5)\n",
        "score"
      ],
      "metadata": {
        "id": "-pdk_rGn68cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving trained Guassian Naive Bayes model"
      ],
      "metadata": {
        "id": "75GyMwA47C6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Dump the trained Naive Bayes classifier with Pickle\n",
        "NB_pkl_filename = '../models/NBClassifier.pkl'\n",
        "# Open the file to save as pkl file\n",
        "NB_Model_pkl = open(NB_pkl_filename, 'wb')\n",
        "pickle.dump(NaiveBayes, NB_Model_pkl)\n",
        "# Close the pickle instances\n",
        "NB_Model_pkl.close()"
      ],
      "metadata": {
        "id": "_fuPnkK57Hg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "spr5NQnz7LgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "# data normalization with sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# fit scaler on training data\n",
        "norm = MinMaxScaler().fit(Xtrain)\n",
        "X_train_norm = norm.transform(Xtrain)\n",
        "# transform testing dataabs\n",
        "X_test_norm = norm.transform(Xtest)\n",
        "SVM = SVC(kernel='poly', degree=3, C=1)\n",
        "SVM.fit(X_train_norm,Ytrain)\n",
        "predicted_values = SVM.predict(X_test_norm)\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('SVM')\n",
        "print(\"SVM's Accuracy is: \", x)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))\n",
        "SVM's Accuracy is:  0.9795454545454545\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "       apple       1.00      1.00      1.00        13\n",
        "      banana       1.00      1.00      1.00        17\n",
        "   blackgram       1.00      1.00      1.00        16\n",
        "    chickpea       1.00      1.00      1.00        21\n",
        "     coconut       1.00      1.00      1.00        21\n",
        "      coffee       1.00      0.95      0.98        22\n",
        "      cotton       0.95      1.00      0.98        20\n",
        "      grapes       1.00      1.00      1.00        18\n",
        "        jute       0.83      0.89      0.86        28\n",
        " kidneybeans       1.00      1.00      1.00        14\n",
        "      lentil       1.00      1.00      1.00        23\n",
        "       maize       1.00      0.95      0.98        21\n",
        "       mango       1.00      1.00      1.00        26\n",
        "   mothbeans       1.00      1.00      1.00        19\n",
        "    mungbean       1.00      1.00      1.00        24\n",
        "   muskmelon       1.00      1.00      1.00        23\n",
        "      orange       1.00      1.00      1.00        29\n",
        "      papaya       1.00      1.00      1.00        19\n",
        "  pigeonpeas       1.00      1.00      1.00        18\n",
        " pomegranate       1.00      1.00      1.00        17\n",
        "        rice       0.80      0.75      0.77        16\n",
        "  watermelon       1.00      1.00      1.00        15\n",
        "\n",
        "    accuracy                           0.98       440\n",
        "   macro avg       0.98      0.98      0.98       440\n",
        "weighted avg       0.98      0.98      0.98       440"
      ],
      "metadata": {
        "id": "L5c7LYpt7Ojc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation score (SVM)\n",
        "score = cross_val_score(SVM,features,target,cv=5)\n",
        "score"
      ],
      "metadata": {
        "id": "_H4NsvPG7UBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving trained SVM model"
      ],
      "metadata": {
        "id": "anp_TTMa7YMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Dump the trained SVM classifier with Pickle\n",
        "SVM_pkl_filename = '../models/SVMClassifier.pkl'\n",
        "# Open the file to save as pkl file\n",
        "SVM_Model_pkl = open(SVM_pkl_filename, 'wb')\n",
        "pickle.dump(SVM, SVM_Model_pkl)\n",
        "# Close the pickle instances\n",
        "SVM_Model_pkl.close()"
      ],
      "metadata": {
        "id": "1Tmt0i8-7bIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "3ytsChsI7jDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LogReg = LogisticRegression(random_state=2)\n",
        "\n",
        "LogReg.fit(Xtrain,Ytrain)\n",
        "\n",
        "predicted_values = LogReg.predict(Xtest)\n",
        "\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('Logistic Regression')\n",
        "print(\"Logistic Regression's Accuracy is: \", x)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))\n",
        "Logistic Regression's Accuracy is:  0.9522727272727273\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "       apple       1.00      1.00      1.00        13\n",
        "      banana       1.00      1.00      1.00        17\n",
        "   blackgram       0.86      0.75      0.80        16\n",
        "    chickpea       1.00      1.00      1.00        21\n",
        "     coconut       1.00      1.00      1.00        21\n",
        "      coffee       1.00      1.00      1.00        22\n",
        "      cotton       0.86      0.90      0.88        20\n",
        "      grapes       1.00      1.00      1.00        18\n",
        "        jute       0.84      0.93      0.88        28\n",
        " kidneybeans       1.00      1.00      1.00        14\n",
        "      lentil       0.88      1.00      0.94        23\n",
        "       maize       0.90      0.86      0.88        21\n",
        "       mango       0.96      1.00      0.98        26\n",
        "   mothbeans       0.84      0.84      0.84        19\n",
        "    mungbean       1.00      0.96      0.98        24\n",
        "   muskmelon       1.00      1.00      1.00        23\n",
        "      orange       1.00      1.00      1.00        29\n",
        "      papaya       1.00      0.95      0.97        19\n",
        "  pigeonpeas       1.00      1.00      1.00        18\n",
        " pomegranate       1.00      1.00      1.00        17\n",
        "        rice       0.85      0.69      0.76        16\n",
        "  watermelon       1.00      1.00      1.00        15\n",
        "\n",
        "    accuracy                           0.95       440\n",
        "   macro avg       0.95      0.95      0.95       440\n",
        "weighted avg       0.95      0.95      0.95       440\n"
      ],
      "metadata": {
        "id": "udBVOCoC7nuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation score (Logistic Regression)\n",
        "score = cross_val_score(LogReg,features,target,cv=5)\n",
        "score"
      ],
      "metadata": {
        "id": "nmILofRA7sQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving trained Logistic Regression model"
      ],
      "metadata": {
        "id": "G2xVN2rj7yU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Dump the trained Naive Bayes classifier with Pickle\n",
        "LR_pkl_filename = '../models/LogisticRegression.pkl'\n",
        "# Open the file to save as pkl file\n",
        "LR_Model_pkl = open(DT_pkl_filename, 'wb')\n",
        "pickle.dump(LogReg, LR_Model_pkl)\n",
        "# Close the pickle instances\n",
        "LR_Model_pkl.close()"
      ],
      "metadata": {
        "id": "SCdptKF971T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "EB15aekd74TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF = RandomForestClassifier(n_estimators=20, random_state=0)\n",
        "RF.fit(Xtrain,Ytrain)\n",
        "\n",
        "predicted_values = RF.predict(Xtest)\n",
        "\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('RF')\n",
        "print(\"RF's Accuracy is: \", x)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))\n",
        "RF's Accuracy is:  0.990909090909091\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "       apple       1.00      1.00      1.00        13\n",
        "      banana       1.00      1.00      1.00        17\n",
        "   blackgram       0.94      1.00      0.97        16\n",
        "    chickpea       1.00      1.00      1.00        21\n",
        "     coconut       1.00      1.00      1.00        21\n",
        "      coffee       1.00      1.00      1.00        22\n",
        "      cotton       1.00      1.00      1.00        20\n",
        "      grapes       1.00      1.00      1.00        18\n",
        "        jute       0.90      1.00      0.95        28\n",
        " kidneybeans       1.00      1.00      1.00        14\n",
        "      lentil       1.00      1.00      1.00        23\n",
        "       maize       1.00      1.00      1.00        21\n",
        "       mango       1.00      1.00      1.00        26\n",
        "   mothbeans       1.00      0.95      0.97        19\n",
        "    mungbean       1.00      1.00      1.00        24\n",
        "   muskmelon       1.00      1.00      1.00        23\n",
        "      orange       1.00      1.00      1.00        29\n",
        "      papaya       1.00      1.00      1.00        19\n",
        "  pigeonpeas       1.00      1.00      1.00        18\n",
        " pomegranate       1.00      1.00      1.00        17\n",
        "        rice       1.00      0.81      0.90        16\n",
        "  watermelon       1.00      1.00      1.00        15\n",
        "\n",
        "    accuracy                           0.99       440\n",
        "   macro avg       0.99      0.99      0.99       440\n",
        "weighted avg       0.99      0.99      0.99       440"
      ],
      "metadata": {
        "id": "Hm4BmWln77qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation score (Random Forest)\n",
        "score = cross_val_score(RF,features,target,cv=5)\n",
        "score"
      ],
      "metadata": {
        "id": "CWzLTZTy8CaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving trained Random Forest model"
      ],
      "metadata": {
        "id": "MdHvlIuR8FXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Dump the trained Naive Bayes classifier with Pickle\n",
        "RF_pkl_filename = '../models/RandomForest.pkl'\n",
        "# Open the file to save as pkl file\n",
        "RF_Model_pkl = open(RF_pkl_filename, 'wb')\n",
        "pickle.dump(RF, RF_Model_pkl)\n",
        "# Close the pickle instances\n",
        "RF_Model_pkl.close()"
      ],
      "metadata": {
        "id": "4E_uxjQf8Idb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "CUGqytKR8LQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "XB = xgb.XGBClassifier()\n",
        "XB.fit(Xtrain,Ytrain)\n",
        "\n",
        "predicted_values = XB.predict(Xtest)\n",
        "\n",
        "x = metrics.accuracy_score(Ytest, predicted_values)\n",
        "acc.append(x)\n",
        "model.append('XGBoost')\n",
        "print(\"XGBoost's Accuracy is: \", x)\n",
        "\n",
        "print(classification_report(Ytest,predicted_values))\n",
        "[14:16:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
        "XGBoost's Accuracy is:  0.9931818181818182\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "       apple       1.00      1.00      1.00        13\n",
        "      banana       1.00      1.00      1.00        17\n",
        "   blackgram       1.00      1.00      1.00        16\n",
        "    chickpea       1.00      1.00      1.00        21\n",
        "     coconut       1.00      1.00      1.00        21\n",
        "      coffee       0.96      1.00      0.98        22\n",
        "      cotton       1.00      1.00      1.00        20\n",
        "      grapes       1.00      1.00      1.00        18\n",
        "        jute       1.00      0.93      0.96        28\n",
        " kidneybeans       1.00      1.00      1.00        14\n",
        "      lentil       0.96      1.00      0.98        23\n",
        "       maize       1.00      1.00      1.00        21\n",
        "       mango       1.00      1.00      1.00        26\n",
        "   mothbeans       1.00      0.95      0.97        19\n",
        "    mungbean       1.00      1.00      1.00        24\n",
        "   muskmelon       1.00      1.00      1.00        23\n",
        "      orange       1.00      1.00      1.00        29\n",
        "      papaya       1.00      1.00      1.00        19\n",
        "  pigeonpeas       1.00      1.00      1.00        18\n",
        " pomegranate       1.00      1.00      1.00        17\n",
        "        rice       0.94      1.00      0.97        16\n",
        "  watermelon       1.00      1.00      1.00        15\n",
        "\n",
        "    accuracy                           0.99       440\n",
        "   macro avg       0.99      0.99      0.99       440\n",
        "weighted avg       0.99      0.99      0.99       440"
      ],
      "metadata": {
        "id": "t4huoS3h8QBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation score (XGBoost)\n",
        "score = cross_val_score(XB,features,target,cv=5)\n",
        "score"
      ],
      "metadata": {
        "id": "6EUC44j48Tgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving trained XGBoost model"
      ],
      "metadata": {
        "id": "PFVkfzYu8bdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Dump the trained Naive Bayes classifier with Pickle\n",
        "XB_pkl_filename = '../models/XGBoost.pkl'\n",
        "# Open the file to save as pkl file\n",
        "XB_Model_pkl = open(XB_pkl_filename, 'wb')\n",
        "pickle.dump(XB, XB_Model_pkl)\n",
        "# Close the pickle instances\n",
        "XB_Model_pkl.close()"
      ],
      "metadata": {
        "id": "JolOfECw8eBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Comparison"
      ],
      "metadata": {
        "id": "ZInwDt148gdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[10,5],dpi = 100)\n",
        "plt.title('Accuracy Comparison')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Algorithm')\n",
        "sns.barplot(x = acc,y = model,palette='dark')"
      ],
      "metadata": {
        "id": "qHjex0aa8pb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_models = dict(zip(model, acc))\n",
        "for k, v in accuracy_models.items():\n",
        "    print (k, '-->', v)"
      ],
      "metadata": {
        "id": "kvT5cOni8qnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a prediction"
      ],
      "metadata": {
        "id": "Gi8yw_g18xqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([[104,18, 30, 23.603016, 60.3, 6.7, 140.91]])\n",
        "prediction = RF.predict(data)\n",
        "print(prediction)\n",
        "['coffee']"
      ],
      "metadata": {
        "id": "ESBpyLFs8y2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([[83, 45, 60, 28, 70.3, 7.0, 150.9]])\n",
        "prediction = RF.predict(data)\n",
        "print(prediction)\n",
        "['jute']"
      ],
      "metadata": {
        "id": "T5tNIQ1D822Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}